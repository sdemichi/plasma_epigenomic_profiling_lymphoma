{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94e0a7b8-6f4c-4368-aa4b-282ed4dad1e2",
   "metadata": {},
   "source": [
    "# Import libraries and set plot dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28a3a839-d1d1-4a38-b079-ea7cdbe9471a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "library(tidyverse)\n",
    "library(edgeR)\n",
    "library(sva)\n",
    "library(reshape2)\n",
    "library(pheatmap)\n",
    "library(RColorBrewer)\n",
    "library(MetBrewer)\n",
    "library(caret)\n",
    "library(glmnet)\n",
    "library(e1071)\n",
    "library(edgeR)\n",
    "library(umap)\n",
    "library(DMwR)\n",
    "library(pROC)\n",
    "library(gbm)\n",
    "library(survival)\n",
    "library(survminer)\n",
    "library(GenomicRanges)\n",
    "library(recipes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1931bc-27a9-4eda-8459-8ea055539054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot dimensions\n",
    "options(repr.plot.width = 10, repr.plot.height = 10) # specific to the IRkernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9e81c3-bea3-4b03-b410-86f10eb4815b",
   "metadata": {},
   "source": [
    "# Data pre-processing + differential analysis (edgeR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1d0447-23f1-4961-97f0-91cb6b9b6815",
   "metadata": {},
   "source": [
    "## Import counts data and compile into a numeric matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f30751-eb49-4360-bff2-b326d752d437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import 10kb reference, w regulatory features and bin IDs. Reference was created using annotatR. Note; reference generation requires an internet connection.\n",
    "setwd(\"/path/to/reference/\")\n",
    "annotated_ref_no_X_Y_M_blacklist <- read.delim(\"10kb_bin_genome_wide_annotated_reference_with_regulatory_features_no_X_Y_M_ENCODEBlacklist.txt\", header = TRUE, sep = \"\\t\")\n",
    "\n",
    "# import sample list, formatted beforehand.\n",
    "setwd(\"/path/to/list/\")\n",
    "sample_list <- read.delim(\"sample_list_for_lymphoma_cohort.txt\", header = TRUE, sep = \"\\t\")\n",
    "\n",
    "gc() #clear memory if memory is a bottleneck; the data frames in this script are large\n",
    "\n",
    "# import non-normalized counts, output from MEDIPS (in 10kb bins)\n",
    "# BAM files prior to generation of non-normalized counts were generated using MEDIPIPE pre-processing pipeline (10.1093/bioinformatics/btad423, originally intended for cfMeDIP-Seq data, but adapted for cfChIP-Seq). \n",
    "setwd(\"/path/to/samples/\")\n",
    "import_counts <- list.files(path = \".\", pattern = \"counts_10kb.txt$\", recursive = TRUE) # list counts with directory paths\n",
    "\n",
    "# exclude samples with these names, as they are not required for the following analyses. Only T1 (baseline) samples should be included.\n",
    "exclude <- c(\"0018_T3\", \"0025_T4\", \"0027_T3\", \"0027_T4\", \"0101_T3\", \"0030_T1\", \"HUCON_37\", \"HUCON_43\", \"HUCON_44\", \"0036_C\", \"0247_T1_ABC\", \"T3\", \"T5\", \"pbmc_k27\") #character vector of sample strings to be excluded.\n",
    "\n",
    "# convert character vector to data frame\n",
    "import_counts <- as.data.frame(import_counts)\n",
    "\n",
    "# Remove all excluded samples from the original list of samples. Use \"|\" as the seperator between vector elements.\n",
    "import_counts <- import_counts[!grepl(paste(exclude, collapse = \"|\"), import_counts$import_counts),] # \n",
    "\n",
    "# loop over files in import_counts, and read them into memory\n",
    "counts <- mapply(read.delim, import_counts) \n",
    "\n",
    "# bind individual datasets across columns\n",
    "counts_matrix <- do.call(cbind, counts)\n",
    "\n",
    "# change column names to file names from list, and remove NAs\n",
    "colnames(counts_matrix) <- c(paste0(sample_list$sample_name))\n",
    "counts_matrix <- na.omit(counts_matrix)\n",
    "\n",
    "# index rows in counts_matrix\n",
    "rownames(counts_matrix) <- 1:nrow(counts_matrix)\n",
    "\n",
    "gc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b47011-947b-43c5-9d38-06563097dbbb",
   "metadata": {},
   "source": [
    "## Data cleaning, filter out low variance and low count features from the matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88601602-a443-4d59-965b-cbcd6cbf092c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter out chrX, Y, and ENCODE Blacklist regions. Resulting data frame is your ground truth; refer back to this after feature selection.\n",
    "all_filtered_features <- counts_matrix[as.integer(rownames(counts_matrix)) %in% annotated_ref_no_X_Y_M_blacklist$bin_id,]\n",
    "\n",
    "# calculate the coefficient of variation (CV, ratio of SD to the mean) for all features using the var function, row-wise. Independent of sample origin.\n",
    "cv_features <- apply(all_filtered_features, 1, var)\n",
    "\n",
    "# visualize histogram of feature variances\n",
    "var_hist <- hist(cv_features[cv_features > 0 & cv_features < 40000], breaks = 500) # bimodal distribution, left skewed\n",
    "\n",
    "# remove variance below the valley on the histogram. Valley is at around 2400.\n",
    "all_filtered_features <- all_filtered_features[(which(apply(all_filtered_features, 1, var)>=2400)),]\n",
    "\n",
    "# remove low count features\n",
    "counts_mean <- apply(all_filtered_features, 1, mean) # left skewed, slight bimodal distribution of counts after filtering low variance features.\n",
    "counts_hist <- hist(counts_mean[counts_mean > 0 & counts_mean < 1000], breaks = 500) \n",
    "\n",
    "# Remove lowest expressed features\n",
    "all_filtered_features <- all_filtered_features[(which(apply(all_filtered_features, 1, mean)>=50)),]\n",
    "\n",
    "gc() #clear memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f449791-cc91-4f80-ad6a-1a6d6619ce16",
   "metadata": {},
   "source": [
    "## Split dataset into train and test sets for feature selection / validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe6c785-58fc-42cc-8331-3269d01e2fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train and test sets. Perform differential analysis on only training set.\n",
    "\n",
    "# Split the data into features (X) and labels (y)\n",
    "X <- all_filtered_features  # Features (numeric matrix plus sample name attributes)\n",
    "y <- sample_list$timepoint # Data labels for lymphoma vs non-lymphoma classification\n",
    "\n",
    "# Training: 70%; Test: 30%\n",
    "# Split the data into training and testing sets\n",
    "set.seed(23)  # For reproducibility\n",
    "\n",
    "train_indices <- createDataPartition(y, p = 0.7, list = FALSE)\n",
    "\n",
    "# save train and test set numeric matrices and labels as independent variables. Lock test set away for later validation.\n",
    "X_train <- X[, train_indices]\n",
    "y_train <- y[train_indices]\n",
    "X_test <- X[, -train_indices]\n",
    "y_test <- y[-train_indices]\n",
    "\n",
    "#check balance of healthy and baseline samples in train/test splits. Ensure it is close to 70/30.\n",
    "table(y_train)\n",
    "table(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d3a06f-2266-416d-8251-dec80be03619",
   "metadata": {},
   "source": [
    "## Perform differential analysis using edgeR, using SVA to address unknown patterns in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2c43a3-b667-4714-ac64-98aae5b17aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this chunk takes time and computational power, so schedule script as a job if working on a virtual machine.\n",
    "# script for differential analysis was adapted from edgeR user guide (https://bioconductor.org/packages/release/bioc/vignettes/edgeR/inst/doc/edgeRUsersGuide.pdf)\n",
    "gc()\n",
    "\n",
    "# set up DGEList object for differential analysis\n",
    "design <- model.matrix(~y_train) #design model around differences between lymphoma and non-lymphoma profiles. Can change depending on intended comparison.\n",
    "list <- DGEList(counts = X_train, samples = y_train, remove.zeros = FALSE) # no need to remove zeros, since they were removed in matrix pre-processing steps.\n",
    "\n",
    "# apply TMM normalization to raw counts\n",
    "tmm_norm <- calcNormFactors(list, method=\"TMM\")\n",
    "\n",
    "# normalize counts before SVA is performed; otherwise library size is the only surrogate variable.\n",
    "cpm_norm <- cpm(tmm_norm, normalized.lib.sizes = TRUE, log = FALSE)\n",
    "\n",
    "# perform SVA analysis to remove technical variation\n",
    "sva_fit <- sva(cpm_norm, design)\n",
    "\n",
    "#IMPORTANT; add SVA surrogate variables as covariates in model design.\n",
    "design <- model.matrix(~y_train + sva_fit$sv)\n",
    "\n",
    "## save model before differential analysis is applied, in case the analysis is not complete within the bounds of the wall time allocated.\n",
    "#save.image()\n",
    "\n",
    "gc()\n",
    "\n",
    "# steps below here are to perform the differential analysis\n",
    "fit <- estimateDisp(tmm_norm, design = design, trend.method = \"locfit\", robust = TRUE)\n",
    "\n",
    "gc()\n",
    "\n",
    "# fit model, incorporating surrogate variables\n",
    "QL <- glmQLFit(fit, design = design)\n",
    "\n",
    "#Subset to rows with an FDR <0.05\n",
    "fdr <- table(p.adjust(QL$table$PValue, method=\"BH\")<0.05)\n",
    "\n",
    "lrt <- glmQLFTest(QL, coef = 2)\n",
    "\n",
    "# extract all features, sorted by p-val\n",
    "res <- topTags(lrt, n = 246275, adjust.method = \"BH\", sort.by = \"PValue\")\n",
    "\n",
    "# save dataset\n",
    "setwd(\"path/to/working/directory/\")\n",
    "save.image(\"train_test_split_for_differential_analysis.RData\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5b1fec-82b5-4cab-a144-f3bb359cb7c6",
   "metadata": {},
   "source": [
    "## Subset to significant features from differential analysis, generate volcano plot of features as sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88daf8c5-5a3a-4086-b3cc-e02bf5016475",
   "metadata": {},
   "outputs": [],
   "source": [
    "setwd(\"path/to/working/directory/\")\n",
    "load(\"train_test_split_for_differential_analysis.RData\")\n",
    "\n",
    "#keep only the features that meet a p-value threshold.\n",
    "#de_features_subset <- res[(res$table$logFC >= 1 | res$table$logFC <= -1) & res$table$PValue <= 0.01,] # logFC >= 1 is 2x change; only 19 features.\n",
    "#de_features_subset <- res[(res$table$logFC >= 0.25 | res$table$logFC <= -0.25) & res$table$PValue <= 0.05,] # 341 features.\n",
    "#de_features_subset <- res[res$table$PValue <= 0.01,] # 1742 features\n",
    "de_features_subset <- res[res$table$PValue <= 0.05,] # 9370 features; stick with this one as it is less stringent. Let the Random Forest decide which features are important.\n",
    "\n",
    "# store feature names (aka bin IDs) for differential features and all features as separate variables\n",
    "de_features <- rownames(de_features_subset)\n",
    "de_features_all <- rownames(res)\n",
    "\n",
    "# calculate logFC, pval, and -log10(pval) for all features\n",
    "logFC <- res$table$logFC\n",
    "p_value <- res$table$PValue\n",
    "neg_log_p_value <- -log10(p_value)\n",
    "\n",
    "# compile data for volcano plot.\n",
    "df_feature_stats <- data.frame(logFC,neg_log_p_value,de_features_all)\n",
    "\n",
    "# calculate logFC, pval, and -log10(pval) for all significant features\n",
    "logFC_signif <- de_features_subset$table$logFC\n",
    "p_value_signif <- de_features_subset$table$PValue\n",
    "neg_log_p_value_signif <- -log10(p_value_signif)\n",
    "\n",
    "# compile data for volcano plot.\n",
    "df_feature_stats_signif <- data.frame(logFC_signif,neg_log_p_value_signif,de_features)\n",
    "\n",
    "v <- ggplot() +\n",
    "  geom_point(data = df_feature_stats, aes(x = logFC, y = neg_log_p_value), colour = \"black\", alpha = 0.3) +\n",
    "  geom_point(data = df_feature_stats_signif, aes(x = logFC_signif, y = neg_log_p_value_signif), colour = \"red\", alpha = 0.3) +\n",
    "  geom_hline(yintercept = -log10(0.05), linetype = \"dashed\", color = \"red\") +\n",
    "  geom_vline(xintercept = c(-1, 1), linetype = \"dashed\", color = \"blue\") +\n",
    "  labs(x = \"Log Fold Change\", y = \"-log10(p-value)\") +\n",
    "  ggtitle(\"Volcano Plot\") +\n",
    "  theme_minimal()\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d90e2d-07dd-4d00-8a87-dfa015059a32",
   "metadata": {},
   "source": [
    "## Perform Principal Component Analysis (PCA) on all significant differential features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d48ad0-37a2-4eaf-a847-31c4a517bd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot PCA of significant features, to see whether the features differentiate between lymphoma profiles and non-lymphoma controls\n",
    "# compare to PCA of all features\n",
    "\n",
    "# ensure you transpose the feature matrix before PCA\n",
    "# pca_data <- t(cpm_norm) # for all features\n",
    "pca_data <- t(cpm_norm[de_features,]) # for feature subset\n",
    "\n",
    "# perform PCA, with z-scaling\n",
    "pca_res <- prcomp(pca_data, scale = TRUE)\n",
    "\n",
    "# Plot the first two principal components. Commented geoms are additional data layers, for additional visualizations.\n",
    "q <- pca_res$x %>% \n",
    "  as.data.frame %>%\n",
    "  ggplot(aes(x=PC1,y=PC2)) +\n",
    "  #geom_point(aes(color=list$samples$DIAGNOSIS_CLASS_SUMMARIZE_HEALTHY),size=5) +\n",
    "  #geom_point(aes(color=list$samples$DIAGNOSIS_CLASS_SUMMARIZE_HEALTHY.DIAGNOSIS_SPECIFIC_DLBCL),size=5) +\n",
    "  #geom_point(aes(color=list$samples$timepoint),size=5) +\n",
    "  geom_point(aes(color=y_train),size=5) +\n",
    "  #geom_point(aes(color=list$samples$batch),size=5) +\n",
    "  #geom_text(aes(label=list$samples$sample_name)) +\n",
    "  theme_minimal(base_size=20) + \n",
    "  labs(colour = \"Group\") +\n",
    "  xlab(paste0(\"PC1 (\", round(pca_res$sdev[1]^2*100/sum(pca_res$sdev^2), 1), \"%)\")) +\n",
    "  ylab(paste0(\"PC2 (\", round(pca_res$sdev[2]^2*100/sum(pca_res$sdev^2), 1), \"%)\")) +\n",
    "  theme(legend.position=\"right\")\n",
    "\n",
    "print(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54afd57b-03cc-4444-9cd0-540e5d9da50d",
   "metadata": {},
   "source": [
    "# Random Forest of significant differential features (additional feature selection step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e70156a-ca9a-4a29-b657-2fd9f5ed7d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunk requires at least 60GB of memory on a virtual machine, run script as a scheduled job on compute cluster, requesting compute node.\n",
    "\n",
    "# import dataset with significant differential features\n",
    "setwd(\"path/to/working/directory/\")\n",
    "load(\"train_test_split_for_differential_analysis.RData\")\n",
    "\n",
    "# subset differential results to differential features\n",
    "de_features_subset <- res[res$table$PValue <= 0.05,] # 9370 features\n",
    "# de_features_subset <- res[res$table$PValue <= 0.05 & res$table$logFC > 0,] # 5328 features; only hypermethylated features considered. Compare classification performance\n",
    "\n",
    "# save bin IDs (aka rownames) of differential features, depending on which set you're using\n",
    "de_features <- rownames(de_features_subset)\n",
    "\n",
    "# subset CPM normalized matrix to differential features\n",
    "de_features_matrix <- cpm_norm[de_features,]\n",
    "\n",
    "# specify tune grid for hyperparameter tuning; tuning hyperparameters depend on the model used.\n",
    "tune_grid <- expand.grid(\n",
    "  mtry = c(2, 5, 10) # tuning hyperparameter for rf. Can test a range of values here, or do a grid search in trainControl\n",
    ")\n",
    "\n",
    "# set up train control for Random Forest model (R Caret).\n",
    "ctrl <- trainControl(\n",
    "  method = \"repeatedcv\",  # Use cross-validation for evaluation\n",
    "  repeats = 5, # number of model iterations\n",
    "  number = 10,  # Number of folds for cross-validation\n",
    "  search = \"grid\",\n",
    "  sampling = \"smote\",\n",
    "  verbose = FALSE\n",
    ")\n",
    "\n",
    "# transpose feature matrix for machine learning\n",
    "t_de_features_matrix <- t(de_features_matrix)\n",
    "\n",
    "model <- train(t_de_features_matrix, \n",
    "               as.factor(y_train), \n",
    "               method = \"rf\", # for Random Forest\n",
    "               # method = \"nb\", # naive bayes; turn off tuneGrid.\n",
    "               # method = \"glmnet\", # try with specifying the tuneLength parameter next\n",
    "               trControl = ctrl, \n",
    "               tuneGrid = tune_grid, # turn off for nb\n",
    "               metric = \"Accuracy\",\n",
    "               #metric = \"ROC\",\n",
    "               #metric = \"Kappa\", # for unbalanced sets; since we're using SMOTE, accuracy should be okay\n",
    "               ntree = 500 # for rf\n",
    "               #tuneLength = 8 # take random values for default tuning parameters and pick the best; alternative to tuneGrid\n",
    ")\n",
    "\n",
    "# print error log for model output, in case the model fails\n",
    "# sink(rf_hyperparameter_tuning_accuracy_error_log.txt)\n",
    "\n",
    "# see model results for training data\n",
    "print(model)\n",
    "\n",
    "# extract predictors for further analysis (aka feature validation)\n",
    "predictors <- predictors(model)\n",
    "\n",
    "# save dataset w model\n",
    "setwd(\"path/to/working/directory/\")\n",
    "save.image(\"rf_model_from_differential_features.RData\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
